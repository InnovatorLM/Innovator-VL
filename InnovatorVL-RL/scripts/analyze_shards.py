import os
import glob
from datasets import load_dataset
from collections import Counter
import pandas as pd

def analyze_shards(root_path, sample_size=5):
    pattern = os.path.join(root_path, "**", "*.parquet")
    files = sorted(glob.glob(pattern, recursive=True))
    
    summary = []
    all_column_stats = Counter()

    print(f"ğŸ” æ­£åœ¨åˆ†æ {len(files)} ä¸ªåˆ†ç‰‡...")

    for f in files:
        try:
            # ä»…åŠ è½½ schema å’Œå‰å‡ è¡Œ
            ds = load_dataset("parquet", data_files=f, split="train")
            num_rows = len(ds)
            columns = ds.column_names
            all_column_stats.update(columns)
            
            # è·å– images å­—æ®µçš„è¯¦ç»†ç±»å‹
            img_type = ds.features.get("images", "Missing")
            
            summary.append({
                "file": os.path.basename(f),
                "path": f,
                "rows": num_rows,
                "columns": ",".join(columns),
                "images_type": str(img_type)
            })
        except Exception as e:
            print(f"âŒ æ— æ³•è¯»å– {f}: {e}")

    # è½¬æ¢æˆ DataFrame æ–¹ä¾¿è§‚å¯Ÿ
    df = pd.DataFrame(summary)
    
    print("\n" + "="*50)
    print("ğŸ“Š å­—æ®µå‡ºç°é¢‘ç‡æ±‡æ€» (ç”¨äºç¡®å®š standard_features):")
    for col, count in all_column_stats.items():
        print(f"- {col}: å­˜åœ¨äº {count}/{len(files)} ä¸ªæ–‡ä»¶ä¸­")
    
    print("\n" + "="*50)
    print("ğŸ–¼ï¸ Images å­—æ®µç±»å‹åˆ†å¸ƒ:")
    print(df["images_type"].value_counts())
    
    # æ‰¾å‡ºé‚£äº›å­—æ®µç¼ºå¤±çš„æ–‡ä»¶
    expected_cols = set(all_column_stats.keys())
    print("\n" + "="*50)
    print("âš ï¸ ç»“æ„å¼‚å¸¸æ£€æŸ¥:")
    for _, row in df.iterrows():
        missing = expected_cols - set(row["columns"].split(","))
        if missing:
            print(f"æ–‡ä»¶ {row['file']} ç¼ºå°‘å­—æ®µ: {missing}")

    return df

# ä½¿ç”¨
df_results = analyze_shards("/mnt/innovator/data/wenzichen/0102_innovator_vl_RL_Data_Merged")