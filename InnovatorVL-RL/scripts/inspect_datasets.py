import os
import glob
from datasets import load_dataset
from tqdm import tqdm

def inspect_datasets(root_path):
    # 1. é€’å½’æŸ¥æ‰¾æ‰€æœ‰ parquet æ–‡ä»¶
    pattern = os.path.join(root_path, "**", "*.parquet")
    files = sorted(glob.glob(pattern, recursive=True))
    
    if not files:
        print(f"âŒ åœ¨ {root_path} ä¸‹æœªæ‰¾åˆ°ä»»ä½• parquet æ–‡ä»¶ã€‚")
        return

    print(f"ğŸ” æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶ï¼Œå¼€å§‹æ£€æŸ¥ç‰¹å¾ç»“æ„...\n")

    reference_features = None
    reference_file = None
    issues_found = 0

    for f in tqdm(files):
        try:
            # ä»…åŠ è½½å…ƒæ•°æ®/ç¬¬ä¸€æ¡æ ·æœ¬ä»¥èŠ‚çœå†…å­˜å’Œæ—¶é—´
            ds = load_dataset("parquet", data_files=f, split="train")
            current_features = ds.features
            
            if reference_features is None:
                reference_features = current_features
                reference_file = f
                print(f"âœ… åŸºå‡†æ–‡ä»¶è®¾å®šä¸º: {os.path.basename(f)}")
                continue
            
            # å¯¹æ¯”ç‰¹å¾
            if current_features != reference_features:
                issues_found += 1
                print(f"\nâŒ [å‘ç°ä¸ä¸€è‡´] æ–‡ä»¶: {f}")
                print(f"   - åŸºå‡†åˆ— ({os.path.basename(reference_file)}): {list(reference_features.keys())}")
                print(f"   - å½“å‰åˆ—: {list(current_features.keys())}")
                
                # ç‰¹åˆ«æ£€æŸ¥æŠ¥é”™çš„ images å­—æ®µ
                if "images" in current_features and "images" in reference_features:
                    if current_features["images"] != reference_features["images"]:
                        print(f"   âš ï¸ è­¦å‘Š: 'images' å­—æ®µç±»å‹å†²çª!")
                        print(f"      åŸºå‡†ç±»å‹: {reference_features['images']}")
                        print(f"      å½“å‰ç±»å‹: {current_features['images']}")
                
                # æ£€æŸ¥æ˜¯å¦å­˜åœ¨æŸä¸€åˆ—åœ¨æŸäº›æ–‡ä»¶ä¸­æ˜¯ Dict, åœ¨æŸäº›æ˜¯ Value(null)
                for col in set(current_features.keys()) & set(reference_features.keys()):
                    if type(current_features[col]) != type(reference_features[col]):
                        print(f"   âš ï¸ è­¦å‘Š: å­—æ®µ '{col}' ç±»å‹ä¸åŒ¹é… (å¯èƒ½ä¼šè§¦å‘ AttributeError)")

        except Exception as e:
            print(f"âŒ æ— æ³•è¯»å–æ–‡ä»¶ {f}: {e}")

    if issues_found == 0:
        print("\nâœ¨ æœªå‘ç°ç»“æ„æ€§å†²çªï¼Œæ‰€æœ‰æ–‡ä»¶çš„ Schema å‡ä¸€è‡´ã€‚")
    else:
        print(f"\nğŸ’¡ æ’æŸ¥å®Œæˆï¼Œå…±å‘ç° {issues_found} ä¸ªæ–‡ä»¶å­˜åœ¨æ½œåœ¨å†²çªã€‚")

# ä½¿ç”¨æ–¹æ³•ï¼š
inspect_datasets("/root/innovator_data_wenzichen/0102_innovator_vl_RL_Data_Merged_debug")